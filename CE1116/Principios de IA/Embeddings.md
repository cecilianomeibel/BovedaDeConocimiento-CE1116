---
Fecha de creación: 2025-09-01 21:59
Fecha de Modificación: 2025-09-01 21:59
tags: 
Tema:
---


## 📚 Idea/Concepto 
Permiten a los modelos entender y procesar el lenguaje humano de manera más efectiva, codificando relaciones semánticas y contextuales entre secuencias de palabras para encontrar similitudes o diferencias. Se pueden ver como una representación vectorial de palabras o frases que se genera durante el entrenamiento del modelo, después de la tokenización. Actúan como una tabla de búsqueda para convertir IDs de tokens en estos vectores. Una característica de los embeddings es que cambian según el contexto destacando su naturaleza aprendible como matrices de pesos y capturan el orden en arquitecturas Transformer.

## 📌 Puntos Claves (Opcional)
- 

## 🔗 Connections
- [[Principios de IA]]

## 💡 Personal Insight (Opcional)
- 
## 🧾 Recursos (Opcional)
- 